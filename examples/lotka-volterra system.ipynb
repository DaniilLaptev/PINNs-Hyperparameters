{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.path.dirname(current_dir), '.'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import pinns\n",
    "\n",
    "# For cleaner output.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $x_0$ and $y_0$, find such $x(t)$ and $y(t)$ : $\\mathbb{R} \\to \\mathbb{R}$, so that\n",
    "\n",
    "$$\\frac{\\mathrm{d}x}{\\mathrm{d}t} = \\alpha x - \\beta x y$$\n",
    "$$\\frac{\\mathrm{d}y}{\\mathrm{d}t} = \\delta x y - \\gamma y$$\n",
    "$$x(0) = x_0, \\quad y(0) = y_0$$\n",
    "\n",
    "We consider problem with following given parameters and initial values: $\\alpha = 0.4, \\beta = 0.1, \\delta = 0.1, \\gamma = 0.6$ and $x_0 = 5, y_0 = 5$ on a domain $[0, 38]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will solve this problem numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# We fix variables for clarity.\n",
    "T = 38\n",
    "alpha, beta, delta, gamma = 0.4, 0.1, 0.1, 0.6\n",
    "x0, y0 = 5.0, 5.0\n",
    "\n",
    "def lotka_volterra(t, u, alpha, beta, delta, gamma):\n",
    "            x, y = u\n",
    "            dx_dt = alpha * x - beta * x * y\n",
    "            dy_dt = delta * x * y - gamma * y\n",
    "            return [dx_dt, dy_dt]\n",
    "\n",
    "t = torch.linspace(0, T, 128)\n",
    "solution = solve_ivp(lotka_volterra, \n",
    "                        (0, T),\n",
    "                        [x0, y0],\n",
    "                        args=(alpha, beta, delta, gamma), \n",
    "                        t_eval=t)\n",
    "x = solution.y[0]\n",
    "y = solution.y[1]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.plot(t, x, label = 'X(t)')\n",
    "plt.plot(t, y, label = 'Y(t)')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our neural network for this task will have one input and two outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns.samplers import ConstantSampler, RandomRectangularSampler\n",
    "\n",
    "constraints_sampler = ConstantSampler((\n",
    "    torch.tensor([[0.]]),\n",
    "    torch.tensor([x0, y0])\n",
    "))\n",
    "\n",
    "domain = {'t': [0, T]}\n",
    "collocation_sampler = RandomRectangularSampler(domain, 2048, return_dict=False)\n",
    "\n",
    "test_points_sampler = ConstantSampler((\n",
    "    t.view(-1, 1), \n",
    "    torch.tensor([x, y]).T\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns.derivatives import Derivative\n",
    "\n",
    "d = Derivative(method = 'autograd')\n",
    "\n",
    "def loss(\n",
    "    cstr_pts, cstr_pred, cstr_vals,\n",
    "    coll_pts, coll_pred,\n",
    "    alpha = 0.4, beta = 0.1, delta = 0.1, gamma = 0.6\n",
    "    ):\n",
    "    \n",
    "    def init_loss(u0, t0):\n",
    "        return torch.mean(torch.square(u0 - cstr_vals))\n",
    "\n",
    "    def ode_loss(u, t):\n",
    "        x = u[:, [0]]\n",
    "        y = u[:, [1]]\n",
    "        \n",
    "        dX = d(x, t)\n",
    "        dY = d(y, t)\n",
    "        \n",
    "        LdX = torch.mean(torch.square(dX - alpha * x + beta * x * y))\n",
    "        LdY = torch.mean(torch.square(dY - delta * x * y + gamma * y))\n",
    "        \n",
    "        return LdX, LdY\n",
    "    \n",
    "    return init_loss(cstr_pred, cstr_pts), *ode_loss(coll_pred, coll_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinns import Trainer\n",
    "from pinns.models import FF\n",
    "from pinns.activations import Sin\n",
    "from pinns.optimizers import Adam\n",
    "from pinns.errors import rmse\n",
    "\n",
    "pinn = FF([1] + [64, 64, 64, 64] + [2], activ=nn.Tanh(), biases=True)\n",
    "pinn.init(nn.init.kaiming_normal_)\n",
    "print(f'Model has {pinn.count_parameters()} trainable parameters.')\n",
    "\n",
    "adam = Adam(pinn, lr = 1e-2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    loss,\n",
    "    pinn,\n",
    "    constraints_sampler,\n",
    "    collocation_sampler,\n",
    "    loss_coefs=[0.8, 0.2, 0.2],    # Coefficients are very important.\n",
    "    test_points_sampler=test_points_sampler\n",
    ")\n",
    "\n",
    "num_iters = 25000\n",
    "save_every = 500\n",
    "\n",
    "def make_plot():\n",
    "    if trainer.iter == 0 or trainer.iter % save_every == 0 or trainer.iter == num_iters:\n",
    "        preds = pinn.predict(test_points_sampler()[0]).detach()\n",
    "        np.save(f'./.temp/lv_{trainer.iter}.npy', preds.numpy())\n",
    "\n",
    "trainer.train(\n",
    "    num_iters=num_iters,\n",
    "    optimizers=[(0, adam)],\n",
    "    validate_every=1,\n",
    "    error_metric = rmse,\n",
    "    at_training_start_callbacks=[make_plot],\n",
    "    at_epoch_end_callbacks=[make_plot],\n",
    "    at_training_end_callbacks=[make_plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinn.model = torch.load('./very_good_model_dont_delete.pt')\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axs[0].plot(trainer.loss_history, label='Loss')\n",
    "axs[0].plot(range(0, trainer.iter + 1, 1), trainer.error_history, label='L2')\n",
    "axs[0].grid()\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].legend()\n",
    "\n",
    "preds = pinn.predict(t.reshape(-1, 1))\n",
    "axs[1].plot(t, x, label = 'x(t)')\n",
    "axs[1].plot(t, y, label = 'y(t)')\n",
    "axs[1].plot(t, preds[:,0].detach(), label='X(t)', linestyle=':')\n",
    "axs[1].plot(t, preds[:,1].detach(), label='Y(t)', linestyle=':')\n",
    "axs[1].grid()\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imageio\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "def save_animation(files, path, duration=5, fps=60, loop=0, type='mp4', processors=2, ):\n",
    "    \n",
    "    fig = plt.figure(figsize=(5, 3))\n",
    "    xlim = t.min(), t.max()\n",
    "    \n",
    "    def plot(i):\n",
    "        preds = np.load(files[i])\n",
    "        # Set plot limits and labels\n",
    "        plt.xlim(xlim)\n",
    "        plt.plot(t, x, label = 'x(t)')\n",
    "        plt.plot(t, y, label = 'y(t)')\n",
    "        plt.plot(t, preds[:,0], label='X(t)', linestyle=':')\n",
    "        plt.plot(t, preds[:,1], label='Y(t)', linestyle=':')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        fig.savefig(f'./.temp/frame_{i}.png', dpi=300)\n",
    "        fig.clear()\n",
    "        \n",
    "    # Number of frames\n",
    "    num_frames = len(files)\n",
    "\n",
    "    # Parallelize the plotting function\n",
    "    Parallel(n_jobs=processors, verbose=4)(delayed(plot)(i) for i in range(num_frames))\n",
    "    \n",
    "    if type == 'mp4':\n",
    "        writer = imageio.get_writer(path, fps=fps)\n",
    "        for i in range(len(files)):\n",
    "            writer.append_data(imageio.imread(f'./.temp/frame_{i}.png'))\n",
    "        writer.close()\n",
    "        \n",
    "    if type == 'gif':\n",
    "        imgs = [Image.open(f'./.temp/frame_{i}.png') for i in range(len(files))]\n",
    "        imgs[0].save(path, save_all=True, append_images=imgs[1:], duration=duration, fps=fps, loop=loop)\n",
    "    \n",
    "files = [f'./.temp/lv_{i}.npy' for i in range(0, trainer.iter, save_every)]\n",
    "save_animation(files, './.results/lotka-volterra animation.gif', type='gif', processors=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
