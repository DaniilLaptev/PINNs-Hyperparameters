{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import grad\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "from utils import FeedForwardNetwork, plot_ode, plot_losses, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DampedHarmonicOscillator:\n",
    "    def __init__(self, T, params, initial_conditions):\n",
    "        \n",
    "        self.T = T\n",
    "        self.d, self.w0 = params\n",
    "        self.init_vals = torch.tensor(initial_conditions)\n",
    "\n",
    "        self.t = torch.linspace(0, self.T, 128)\n",
    "        self.solution = self._solve()\n",
    "    \n",
    "    def loss_initial(self, model):\n",
    "        zero = torch.tensor([0.], requires_grad=True)\n",
    "        x = model(zero)\n",
    "        v = grad(x, zero, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "        return torch.mean(torch.square(torch.hstack([x, v]) - self.init_vals))\n",
    "    \n",
    "    def loss_physical(self, model, t):\n",
    "        x = model(t)\n",
    "        v = grad(x, t, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "        a = grad(v, t, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "        \n",
    "        return torch.mean(torch.square(a + 2*self.d*self.w0 * v + self.w0**2 * x))\n",
    "    \n",
    "    def _solve(self):\n",
    "        def harmonic_oscillator(t, y, d, w0):\n",
    "            x, v = y\n",
    "            dxdt = v\n",
    "            dvdt = -2*d*w0 * v - w0**2 * x\n",
    "            return [dxdt, dvdt]\n",
    "\n",
    "        solution = solve_ivp(harmonic_oscillator, \n",
    "                             (0, self.T), \n",
    "                             self.init_vals, \n",
    "                             args=(self.d, self.w0), \n",
    "                             t_eval=self.t)\n",
    "        return solution.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    problem,\n",
    "    model,\n",
    "    alpha, beta, N_F,\n",
    "    num_iters, lr,\n",
    "    print_every=1000, collect_every=1000\n",
    "):\n",
    "    collocation_t = torch.linspace(0, problem.T, N_F, requires_grad=True).reshape(-1, 1)\n",
    "    test_points = torch.linspace(0, problem.T, 128).reshape(-1, 1)\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for i in range(0, num_iters + 1):\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        L_I = problem.loss_initial(model)\n",
    "        L_F = problem.loss_physical(model, collocation_t)\n",
    "    \n",
    "        L = alpha * L_I + beta * L_F\n",
    "        \n",
    "        L.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if i % print_every == 0 and i > 0:\n",
    "            predicts = model(test_points).flatten().detach().numpy()\n",
    "            print(f'Iteration {i} --- Loss {L.item()} --- RMSE {rmse(predicts, problem.numerical_solution)}')\n",
    "            \n",
    "        if collect_every > 0 and i % collect_every == 0:\n",
    "            predicts = model(test_points).flatten().detach().numpy()\n",
    "            losses.append(np.array([L.item(), rmse(predicts, problem.numerical_solution)]))\n",
    "    \n",
    "    return np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "zeta, omega = 0.2, 2.0\n",
    "x_0, v_0 = 5.0, 7.0\n",
    "problem = DampedHarmonicOscillator(T, (zeta, omega), (x_0, v_0))\n",
    "\n",
    "L, W = 2, 64\n",
    "model = FeedForwardNetwork(2, 64)\n",
    "\n",
    "alpha, beta = 1.0, 0.5\n",
    "N_F = 256\n",
    "num_iters, lr = 2500, 1e-3\n",
    "\n",
    "losses, errors = train(\n",
    "    problem=problem,\n",
    "    model=model,\n",
    "    alpha=alpha, beta=beta, N_F=N_F,\n",
    "    num_iters=num_iters, lr=lr,\n",
    "    print_every=2500, collect_every=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(problem.t.reshape(-1, 1)).detach().flatten().numpy()\n",
    "plot_ode(\n",
    "    problem.t.numpy(), \n",
    "    predicted=[(predictions, 'Neural Network')], \n",
    "    solutions=[(problem.numerical_solution, 'Numerical Solution')], \n",
    "    size=(5, 3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(\n",
    "    t=np.arange(0, num_iters+1, 500),\n",
    "    losses=[(losses, 'Loss Value')],\n",
    "    errors=[(errors, 'RMSE')]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
