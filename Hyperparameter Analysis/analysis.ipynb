{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots\n",
    "plt.style.use(['science'])\n",
    "matplotlib.rcParams[\"font.size\"] = \"12\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import grad\n",
    "\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, hidden_layers, hidden_dim, input_dim=1, output_dim=1, init_rule=torch.nn.init.uniform_):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        \n",
    "        self.L = hidden_layers\n",
    "        self.W = hidden_dim\n",
    "        \n",
    "        self.model = nn.Sequential()\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        inp_linear = nn.Linear(input_dim, hidden_dim)\n",
    "        init_rule(inp_linear.weight)\n",
    "        out_linear = nn.Linear(hidden_dim, output_dim)\n",
    "        init_rule(out_linear.weight)\n",
    "        \n",
    "        self.model.add_module('input', inp_linear)\n",
    "        self.model.add_module('activ0', self.activation)\n",
    "        for i in range(hidden_layers - 1):\n",
    "            linear = nn.Linear(hidden_dim, hidden_dim)\n",
    "            init_rule(linear.weight)\n",
    "            self.model.add_module(f'linear{i+1}', linear)\n",
    "            self.model.add_module(f'activ{i+1}', self.activation)\n",
    "        self.model.add_module('output', out_linear)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def weights_norm(self):\n",
    "        norms = []\n",
    "        with torch.no_grad():\n",
    "            for name, parameter in self.model.named_parameters():\n",
    "                norms.append(torch.linalg.norm(parameter))\n",
    "        return np.array(norms)\n",
    "    \n",
    "    def init_weights(self, initialization):\n",
    "        for param in self.model.parameters():\n",
    "            if len(param.shape) > 1:\n",
    "                initialization(param)\n",
    "                \n",
    "def rmse(predicts, target):\n",
    "    '''\n",
    "    Note that for diffusion both arrays have shape (T, X).\n",
    "    '''\n",
    "    return np.sqrt(np.square(predicts - target).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lotka-Volterra Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lotkavolterra(\n",
    "    t, predictions, numerical, title=None, figsize=(5, 5), \n",
    "    show=True, save=False, path='./plot', dpi=300\n",
    "    ):\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.plot(t, predictions[0], label=r'$\\mathcal{X}(t)$')\n",
    "    plt.plot(t, predictions[1], label=r'$\\mathcal{Y}(t)$')\n",
    "    plt.plot(t, numerical[0], label=r'$x(t)$')\n",
    "    plt.plot(t, numerical[1], label=r'$y(t)$')\n",
    "    \n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel('Population size')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'{path}.png', dpi=dpi)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LotkaVolterraProblem:\n",
    "    def __init__(self, T, params, initial_conditions):\n",
    "        \n",
    "        self.T = T\n",
    "        self.alpha, self.beta, self.delta, self.gamma = params\n",
    "        self.init_vals = torch.tensor(initial_conditions)\n",
    "\n",
    "        self.numerical_solution = self._solve()\n",
    "    \n",
    "    def loss_initial(self, model):\n",
    "        zero = torch.tensor([0.], requires_grad=True)\n",
    "        x = model(zero)\n",
    "        return torch.mean(torch.square(x - self.init_vals))\n",
    "    \n",
    "    def loss_physical(self, model, t):\n",
    "        xy = model(t)\n",
    "        x = xy[:,[0]]\n",
    "        y = xy[:,[1]]\n",
    "\n",
    "        dX = grad(x, t, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "        dY = grad(y, t, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "        \n",
    "        loss_dX = torch.mean(torch.square(dX - self.alpha * x + self.beta * x * y))\n",
    "        loss_dY = torch.mean(torch.square(dY - self.delta * x * y + self.gamma * y))\n",
    "        \n",
    "        return loss_dX, loss_dY\n",
    "    \n",
    "    def _solve(self):\n",
    "        def lotka_volterra(t, y, alpha, beta, delta, gamma):\n",
    "            x, y = y\n",
    "            dx_dt = alpha * x - beta * x * y\n",
    "            dy_dt = delta * x * y - gamma * y\n",
    "            return [dx_dt, dy_dt]\n",
    "\n",
    "        solution = solve_ivp(lotka_volterra, \n",
    "                             (0, self.T),\n",
    "                             self.init_vals, \n",
    "                             method='RK45',\n",
    "                             args=(self.alpha, self.beta, self.delta, self.gamma), \n",
    "                             t_eval=np.linspace(0, self.T, 128))\n",
    "        \n",
    "        return solution.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LotkaVolterraTraining(\n",
    "    problem,\n",
    "    model,\n",
    "    w1, w2, w3, num_iters, N_D, lr,\n",
    "    print_every=0, collect_every=0, save_every=0\n",
    "):\n",
    "    test_points = torch.linspace(0, problem.T, 128).reshape(-1, 1)\n",
    "    t = torch.linspace(0, problem.T, N_D, requires_grad=True).reshape(-1, 1)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, errors = [], []\n",
    "\n",
    "    for i in range(num_iters + 1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        L_I = problem.loss_initial(model)\n",
    "        L_X, L_Y = problem.loss_physical(model, t)\n",
    "\n",
    "        L = w1 * L_I + w2 * L_X + w3 * L_Y\n",
    "\n",
    "        L.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if collect_every > 0 and i % collect_every == 0:\n",
    "            preds = model(test_points).detach().numpy()\n",
    "            x = preds[:,0].flatten()\n",
    "            y = preds[:,1].flatten()\n",
    "\n",
    "            error = (rmse(x, problem.numerical_solution[0]) + rmse(y, problem.numerical_solution[1])) / 2\n",
    "\n",
    "            losses.append(np.array([L_I.item(), L_X.item(), L_Y.item(), L.  item()]))\n",
    "            errors.append(error)\n",
    "        \n",
    "        if print_every > 0 and i % print_every == 0:\n",
    "            print(f'Iteration {i} --- RMSE {error}')\n",
    "                \n",
    "        if save_every > 0 and i % save_every == 0:\n",
    "            plot_lotkavolterra(\n",
    "            test_points, [x, y], problem.numerical_solution, title=f'Iteration {i}', figsize=(6, 4), show=False, save=True, path=f'./training/lotkavolterra/Iteration {i}'\n",
    "        )\n",
    "    \n",
    "    return np.array(losses), np.array(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Diffusion Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diffusion(x, t, predictions, size=(10, 5), show=True, save=False, path='./plot', dpi=300):\n",
    "    X, T = np.meshgrid(x, t)\n",
    "    fig = plt.figure(figsize=size)\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "    ax.plot_surface(X, T, predictions, cmap='viridis')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('t')\n",
    "\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(predictions, origin='lower', aspect='auto', cmap='viridis', \n",
    "              extent=[x.min(), x.max(), t.min(), t.max()])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('t')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'{path}.png', dpi=dpi)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionProblem:\n",
    "    def __init__(self, D, boundaries, resolution, b_values):\n",
    "        self.D = D\n",
    "        self.L, self.R, self.T = boundaries\n",
    "        self.left_boundary, self.right_boundary, self.initial_values = b_values\n",
    "        \n",
    "        self.Nt, self.Nx = resolution\n",
    "        self.numerical_solution = self._solve()\n",
    "        self.t = torch.linspace(0, self.T, self.Nt)\n",
    "        self.x = torch.linspace(self.L, self.R, self.Nx)\n",
    "    \n",
    "    def loss_boundary(self, model, t_left, t_right, x_init):\n",
    "        \n",
    "        def nearest_index(array, values):\n",
    "            values = [np.abs(array - v).argmin() for v in values]\n",
    "            return values\n",
    "        \n",
    "        left_values =  self.left_boundary[nearest_index(self.t, t_left)  ]\n",
    "        right_values = self.right_boundary[nearest_index(self.t, t_right)]\n",
    "        init_values =  self.initial_values[nearest_index(self.x, x_init) ]\n",
    "        \n",
    "        left =  model(torch.vstack([torch.ones_like(t_left)  * self.L, t_left]).T)\n",
    "        right = model(torch.vstack([torch.ones_like(t_right) * self.R, t_right]).T)\n",
    "        init =  model(torch.vstack([x_init, torch.zeros_like(x_init)]).T)\n",
    "        \n",
    "        left_error = torch.square(left_values - left.flatten()).mean()\n",
    "        right_error = torch.square(right_values - right.flatten()).mean()\n",
    "        init_error = torch.square(init_values - init.flatten()).mean()\n",
    "        \n",
    "        return left_error + right_error, init_error\n",
    "    \n",
    "    def loss_physical(self, model, x, t):\n",
    "        u = model(torch.hstack([x, t]))\n",
    "        \n",
    "        ut =  grad(u,  t, grad_outputs=torch.ones_like(t), create_graph=True)[0]\n",
    "        ux =  grad(u,  x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "        uxx = grad(ux, x, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "    \n",
    "        return torch.mean(torch.square(ut - self.D * uxx))\n",
    "        \n",
    "    def _solve(self):\n",
    "        Nt, Nx = self.Nt, self.Nx\n",
    "        \n",
    "        dx = (self.R - self.L) / Nx     # Spatial step size\n",
    "        dt = self.T / Nt                # Time step size\n",
    "        alpha = self.D * dt / (2 * dx ** 2)\n",
    "\n",
    "        # Crank-Nicholson method\n",
    "        u = np.zeros((Nt, Nx))\n",
    "\n",
    "        # Initial condition\n",
    "        u[0, :] = self.initial_values\n",
    "\n",
    "        # Boundary conditions\n",
    "        u[:, 0], u[:, -1] = self.left_boundary, self.right_boundary\n",
    "\n",
    "        A = np.diag((1 + 2*alpha) * np.ones(Nx)) + np.diag(-alpha * np.ones(Nx-1), 1) + np.diag(-alpha * np.ones(Nx-1), -1)\n",
    "        B = np.diag((1 - 2*alpha) * np.ones(Nx)) + np.diag(alpha * np.ones(Nx-1), 1) + np.diag(alpha * np.ones(Nx-1), -1)\n",
    "            \n",
    "        A_reversed = np.linalg.inv(A)\n",
    "\n",
    "        for n in range(0, Nt - 1):\n",
    "            b = np.dot(B, u[n, :])\n",
    "            u[n+1, :] = A_reversed @ b\n",
    "\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion(\n",
    "    problem,\n",
    "    model,\n",
    "    N_LB, N_RB, N_I, N_D,\n",
    "    coef, lr, num_iters,\n",
    "    print_every=0, collect_every=0, save_every=0\n",
    "):\n",
    "\n",
    "    x_sampled = torch.tensor(np.random.uniform(problem.L, problem.R, N_I), dtype=torch.float32)\n",
    "    t_left_sampled =  torch.tensor(np.random.uniform(0, problem.T, N_LB), dtype=torch.float32)\n",
    "    t_right_sampled = torch.tensor(np.random.uniform(0, problem.T, N_RB), dtype=torch.float32)\n",
    "\n",
    "    x_pts = torch.tensor(np.random.uniform(problem.L, problem.R, N_D), requires_grad=True, dtype=torch.float32).reshape(-1, 1)\n",
    "    t_pts = torch.tensor(np.random.uniform(0, problem.T, N_D), requires_grad=True, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    test_points = torch.cartesian_prod(problem.x, problem.t)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, errors = [], []\n",
    "\n",
    "    for i in range(num_iters + 1):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        L_B, L_I = problem.loss_boundary(model, t_left_sampled, t_right_sampled, x_sampled)\n",
    "        L_D = problem.loss_physical(model, x_pts, t_pts)\n",
    "\n",
    "        total = coef * (L_B + L_I) + (1 - coef) * L_D\n",
    "\n",
    "        total.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "        if collect_every > 0 and i % collect_every == 0:\n",
    "            preds = model(test_points).reshape(problem.Nx, problem.Nt).detach().numpy()\n",
    "                \n",
    "            error = rmse(preds.T, problem.numerical_solution)\n",
    "                \n",
    "            losses.append(np.array([L_I.item(), L_B.item(), L_D.item(), total.item()]))\n",
    "            errors.append(error)\n",
    "                \n",
    "        if print_every > 0 and i % print_every == 0:\n",
    "            print(f'Iteration {i} --- RMSE {error}')\n",
    "                \n",
    "        if save_every > 0 and i % save_every == 0:\n",
    "            plot_diffusion(problem.x, problem.t, preds.T, show=False, save=True, path=f'./training/diffusion/Iteration {i}')\n",
    "                \n",
    "    return np.array(losses), np.array(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Initialization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_methods = [\n",
    "    (torch.nn.init.eye_, 'Eye'),\n",
    "    (torch.nn.init.zeros_, 'Zeros'),\n",
    "    (torch.nn.init.normal_, 'Normal'),\n",
    "    (torch.nn.init.uniform_, 'Uniform'),\n",
    "    (torch.nn.init.orthogonal_, 'Orthogonal'),\n",
    "    (torch.nn.init.kaiming_normal_, 'Kaiming Normal'),\n",
    "    (torch.nn.init.kaiming_uniform_, 'Kaiming Uniform'),\n",
    "]\n",
    "\n",
    "num_trainings = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem = LotkaVolterraProblem(\n",
    "#     25., (0.4, 0.1, 0.1, 0.6), [10., 5.]\n",
    "#     )\n",
    "\n",
    "# w1, w2, w3 = 1, 2, 2\n",
    "# num_iters = 20000\n",
    "# N_D = 1024\n",
    "# lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = 0.5\n",
    "# L, R, T = 0, 1, 0.5\n",
    "# Nt, Nx = 1000, 250\n",
    "# left_boundary = right_boundary = torch.zeros(Nt)\n",
    "# initial_conditions = torch.sin(2 * np.pi * torch.linspace(L, R, Nx)) ** 2\n",
    "\n",
    "# problem = DiffusionProblem(\n",
    "#     D, (L, R, T), (Nt, Nx),\n",
    "#     (left_boundary, right_boundary, initial_conditions)\n",
    "# )\n",
    "\n",
    "# N_I, N_LB, N_RB, N_D = 128, 64, 64, 2048\n",
    "# coef = 0.8\n",
    "# lr = 1e-3\n",
    "# num_iters = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_report(n_rows, lv_threshold, diff_threshold):\n",
    "\n",
    "    lv = pd.read_csv('./lotkavolterra_initializations.csv', names=['Method', 'RMSE'])\n",
    "    lv['Task'] = ['Lotka-Volterra' for _ in range(n_rows)]\n",
    "    lv['Class'] = lv['RMSE'] < lv_threshold\n",
    "    \n",
    "    diff = pd.read_csv('./diffusion_initializations.csv', names=['Method', 'RMSE'])\n",
    "    diff['Task'] = ['Diffusion' for _ in range(n_rows)]\n",
    "    diff['Class'] = diff['RMSE'] < diff_threshold\n",
    "    \n",
    "    return pd.concat([lv, diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = get_report(\n",
    "    len(init_methods) * num_trainings,\n",
    "    lv_threshold=0.2, diff_threshold=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = report.groupby(['Task', 'Class', 'Method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th>Class</th>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">Diffusion</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">False</th>\n",
       "      <th>Eye</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.01016</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>0.013755</td>\n",
       "      <td>0.014780</td>\n",
       "      <td>0.01703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiming Normal</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.011967</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.01061</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.01537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiming Uniform</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.01067</td>\n",
       "      <td>0.010720</td>\n",
       "      <td>0.010770</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.01380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.036533</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.02553</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>0.035870</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.04328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ones</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.182225</td>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.149110</td>\n",
       "      <td>0.149220</td>\n",
       "      <td>0.151880</td>\n",
       "      <td>0.54526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthogonal</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.004693</td>\n",
       "      <td>0.01004</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.016975</td>\n",
       "      <td>0.02546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniform</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.072469</td>\n",
       "      <td>0.028925</td>\n",
       "      <td>0.04633</td>\n",
       "      <td>0.059695</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.071820</td>\n",
       "      <td>0.14884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Normal</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.016355</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.01057</td>\n",
       "      <td>0.012490</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>0.02360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Uniform</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.01085</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.021860</td>\n",
       "      <td>0.03156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeros</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.035585</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.01420</td>\n",
       "      <td>0.029305</td>\n",
       "      <td>0.037370</td>\n",
       "      <td>0.044005</td>\n",
       "      <td>0.05226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">True</th>\n",
       "      <th>Eye</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.007483</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.00631</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.007270</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.00916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiming Normal</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.008625</td>\n",
       "      <td>0.00937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiming Uniform</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.00561</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.00960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthogonal</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.007618</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.00494</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.007860</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.00981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Normal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.00798</td>\n",
       "      <td>0.008167</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.00873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Uniform</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.00748</td>\n",
       "      <td>0.007865</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.008635</td>\n",
       "      <td>0.00902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">Lotka-Volterra</th>\n",
       "      <th rowspan=\"10\" valign=\"top\">False</th>\n",
       "      <th>Eye</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.473254</td>\n",
       "      <td>1.813184</td>\n",
       "      <td>0.25713</td>\n",
       "      <td>4.385800</td>\n",
       "      <td>4.386110</td>\n",
       "      <td>4.386120</td>\n",
       "      <td>4.39150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiming Normal</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.909422</td>\n",
       "      <td>1.416706</td>\n",
       "      <td>0.29652</td>\n",
       "      <td>4.386085</td>\n",
       "      <td>4.386840</td>\n",
       "      <td>4.406385</td>\n",
       "      <td>4.69924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kaiming Uniform</th>\n",
       "      <td>15.0</td>\n",
       "      <td>3.917881</td>\n",
       "      <td>1.433695</td>\n",
       "      <td>0.38375</td>\n",
       "      <td>4.386705</td>\n",
       "      <td>4.387270</td>\n",
       "      <td>4.392865</td>\n",
       "      <td>4.84333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.518866</td>\n",
       "      <td>2.102591</td>\n",
       "      <td>0.20056</td>\n",
       "      <td>0.259740</td>\n",
       "      <td>4.377720</td>\n",
       "      <td>4.385470</td>\n",
       "      <td>4.39779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ones</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2.155833</td>\n",
       "      <td>0.354404</td>\n",
       "      <td>1.83784</td>\n",
       "      <td>1.945140</td>\n",
       "      <td>2.017210</td>\n",
       "      <td>2.119745</td>\n",
       "      <td>2.81926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthogonal</th>\n",
       "      <td>15.0</td>\n",
       "      <td>4.386090</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>4.38378</td>\n",
       "      <td>4.386125</td>\n",
       "      <td>4.386320</td>\n",
       "      <td>4.386420</td>\n",
       "      <td>4.38696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uniform</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.589525</td>\n",
       "      <td>1.184310</td>\n",
       "      <td>0.58618</td>\n",
       "      <td>0.940340</td>\n",
       "      <td>1.062890</td>\n",
       "      <td>1.588285</td>\n",
       "      <td>4.38542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Normal</th>\n",
       "      <td>13.0</td>\n",
       "      <td>4.386182</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>4.38479</td>\n",
       "      <td>4.386280</td>\n",
       "      <td>4.386370</td>\n",
       "      <td>4.386480</td>\n",
       "      <td>4.38672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Uniform</th>\n",
       "      <td>14.0</td>\n",
       "      <td>4.386829</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>4.38117</td>\n",
       "      <td>4.386627</td>\n",
       "      <td>4.386735</td>\n",
       "      <td>4.387093</td>\n",
       "      <td>4.39165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeros</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.317960</td>\n",
       "      <td>0.051653</td>\n",
       "      <td>0.24831</td>\n",
       "      <td>0.282020</td>\n",
       "      <td>0.318850</td>\n",
       "      <td>0.350290</td>\n",
       "      <td>0.39394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">True</th>\n",
       "      <th>Eye</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.126517</td>\n",
       "      <td>0.053698</td>\n",
       "      <td>0.03155</td>\n",
       "      <td>0.116322</td>\n",
       "      <td>0.129595</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>0.18120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075320</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>0.069270</td>\n",
       "      <td>0.075320</td>\n",
       "      <td>0.081370</td>\n",
       "      <td>0.08742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Normal</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>0.10353</td>\n",
       "      <td>0.117820</td>\n",
       "      <td>0.132110</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.16069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xavier Uniform</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08793</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.08793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeros</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.040315</td>\n",
       "      <td>0.024056</td>\n",
       "      <td>0.02340</td>\n",
       "      <td>0.026152</td>\n",
       "      <td>0.031480</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.09674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      RMSE                               \\\n",
       "                                     count      mean       std      min   \n",
       "Task           Class Method                                               \n",
       "Diffusion      False Eye               8.0  0.013830  0.002247  0.01016   \n",
       "                     Kaiming Normal    4.0  0.011967  0.002275  0.01061   \n",
       "                     Kaiming Uniform   3.0  0.011747  0.001779  0.01067   \n",
       "                     Normal           15.0  0.036533  0.005249  0.02553   \n",
       "                     Ones             15.0  0.182225  0.102934  0.14910   \n",
       "                     Orthogonal       11.0  0.014235  0.004693  0.01004   \n",
       "                     Uniform          15.0  0.072469  0.028925  0.04633   \n",
       "                     Xavier Normal    13.0  0.016355  0.004651  0.01057   \n",
       "                     Xavier Uniform   13.0  0.018112  0.006489  0.01085   \n",
       "                     Zeros            15.0  0.035585  0.010856  0.01420   \n",
       "               True  Eye               7.0  0.007483  0.000934  0.00631   \n",
       "                     Kaiming Normal   11.0  0.007046  0.001555  0.00517   \n",
       "                     Kaiming Uniform  12.0  0.008048  0.001216  0.00561   \n",
       "                     Orthogonal        4.0  0.007618  0.002155  0.00494   \n",
       "                     Xavier Normal     2.0  0.008355  0.000530  0.00798   \n",
       "                     Xavier Uniform    2.0  0.008250  0.001089  0.00748   \n",
       "Lotka-Volterra False Eye               9.0  3.473254  1.813184  0.25713   \n",
       "                     Kaiming Normal   15.0  3.909422  1.416706  0.29652   \n",
       "                     Kaiming Uniform  15.0  3.917881  1.433695  0.38375   \n",
       "                     Normal           13.0  2.518866  2.102591  0.20056   \n",
       "                     Ones             15.0  2.155833  0.354404  1.83784   \n",
       "                     Orthogonal       15.0  4.386090  0.000791  4.38378   \n",
       "                     Uniform          15.0  1.589525  1.184310  0.58618   \n",
       "                     Xavier Normal    13.0  4.386182  0.000606  4.38479   \n",
       "                     Xavier Uniform   14.0  4.386829  0.002153  4.38117   \n",
       "                     Zeros             7.0  0.317960  0.051653  0.24831   \n",
       "               True  Eye               6.0  0.126517  0.053698  0.03155   \n",
       "                     Normal            2.0  0.075320  0.017112  0.06322   \n",
       "                     Xavier Normal     2.0  0.132110  0.040418  0.10353   \n",
       "                     Xavier Uniform    1.0  0.087930       NaN  0.08793   \n",
       "                     Zeros             8.0  0.040315  0.024056  0.02340   \n",
       "\n",
       "                                                                             \n",
       "                                           25%       50%       75%      max  \n",
       "Task           Class Method                                                  \n",
       "Diffusion      False Eye              0.013125  0.013755  0.014780  0.01703  \n",
       "                     Kaiming Normal   0.010797  0.010945  0.012115  0.01537  \n",
       "                     Kaiming Uniform  0.010720  0.010770  0.012285  0.01380  \n",
       "                     Normal           0.033435  0.035870  0.040985  0.04328  \n",
       "                     Ones             0.149110  0.149220  0.151880  0.54526  \n",
       "                     Orthogonal       0.010645  0.012840  0.016975  0.02546  \n",
       "                     Uniform          0.059695  0.061700  0.071820  0.14884  \n",
       "                     Xavier Normal    0.012490  0.015300  0.021470  0.02360  \n",
       "                     Xavier Uniform   0.013870  0.015370  0.021860  0.03156  \n",
       "                     Zeros            0.029305  0.037370  0.044005  0.05226  \n",
       "               True  Eye              0.007040  0.007270  0.007780  0.00916  \n",
       "                     Kaiming Normal   0.005740  0.006670  0.008625  0.00937  \n",
       "                     Kaiming Uniform  0.007310  0.008040  0.008960  0.00960  \n",
       "                     Orthogonal       0.006410  0.007860  0.009067  0.00981  \n",
       "                     Xavier Normal    0.008167  0.008355  0.008542  0.00873  \n",
       "                     Xavier Uniform   0.007865  0.008250  0.008635  0.00902  \n",
       "Lotka-Volterra False Eye              4.385800  4.386110  4.386120  4.39150  \n",
       "                     Kaiming Normal   4.386085  4.386840  4.406385  4.69924  \n",
       "                     Kaiming Uniform  4.386705  4.387270  4.392865  4.84333  \n",
       "                     Normal           0.259740  4.377720  4.385470  4.39779  \n",
       "                     Ones             1.945140  2.017210  2.119745  2.81926  \n",
       "                     Orthogonal       4.386125  4.386320  4.386420  4.38696  \n",
       "                     Uniform          0.940340  1.062890  1.588285  4.38542  \n",
       "                     Xavier Normal    4.386280  4.386370  4.386480  4.38672  \n",
       "                     Xavier Uniform   4.386627  4.386735  4.387093  4.39165  \n",
       "                     Zeros            0.282020  0.318850  0.350290  0.39394  \n",
       "               True  Eye              0.116322  0.129595  0.163845  0.18120  \n",
       "                     Normal           0.069270  0.075320  0.081370  0.08742  \n",
       "                     Xavier Normal    0.117820  0.132110  0.146400  0.16069  \n",
       "                     Xavier Uniform   0.087930  0.087930  0.087930  0.08793  \n",
       "                     Zeros            0.026152  0.031480  0.043147  0.09674  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def percent(a):\n",
    "    return a / 15 * 100\n",
    "\n",
    "percent(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
